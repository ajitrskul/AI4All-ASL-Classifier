# ASL Classifier (AI4ALL)

Created and implemented a computer vision model to classify ASL alphabet letters utilizing Python and image manipulation methodology. Built under the AI4All Ignite Accelerator program in Fall 2024.

## Problem Statement

Accessibility for the hearing impaired on the internet, and in general, has been an on going topic of intense discussion by software engineers across the world. With the fast paced nature of technological advancement as well
as the structure of the internet and related technological infrastructure, it is extremely critical that hearing-impaired users are not left behind in our ceaseless drive for innovation.

## Key Results 

1. Trained a CNN on 87,000 200 x 200 pixel images for ASL Classification
2. Achieved a classification accuracy of nearly __% on training data and __% on testing data


## Methodologies 
To accomplish this, we exported a kaggle ASL dataset to utilize for training and split the data into training and testing groups. Utilizing pandas, numpy, openCV, tensorflow and keras, we used supervised learning to train a convolutional neural network to recognize ASL alphabet letters at a level of accuracy comparable to some humans. 

## Data Sources 

*ASL Kaggle Dataset: [Link to Kaggle Dataset]([https://www.kaggle.com/datasets](https://www.kaggle.com/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset/data))*

## Technologies Used

- *Python*
- *pandas*
- *numpy*
- *openCV*
- *keras*
- *tensorflow*


## Authors
*This project was completed by:*
- *Aurora Jitrskul ([ajitrskul@tamu.edu](mailto:ajitrskul@tamu.edu))*
- *With the following Contributor:*
  - *Devanshi Kothuri ([devanshikothari5@gmail.com](mailto:devanshikothari5@gmail.com))*
