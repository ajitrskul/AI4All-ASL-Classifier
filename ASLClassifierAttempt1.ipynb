{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RYjv_IIJZSjvDsQOztD5-Jx4-fX5wbNM",
      "authorship_tag": "ABX9TyPrGfCrCtkCF0+ukO24DAsl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRNMEAY5knR7",
        "outputId": "921c3899-dacb-430e-b024-5ce5f79c8f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "#Installing dependent libraries\n",
        "\n",
        "!pip install opendatasets\n",
        "!pip install pandas\n",
        "!pip install -q kaggle\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check tensorflow version for incompatibilities\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlIXa-s8d8OJ",
        "outputId": "bd93a79a-b557-4deb-80bd-408e4c10995c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE1UFSpWlbUM",
        "outputId": "c76da546-f532-4551-ad9b-78ec9734195d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert your folder path for zipped dataset here\n",
        "zip_file_path = r\"/content/drive/MyDrive/TAMU Junior Year/AI4All/AI4ALL-Class-16-Group-2/ASL Dataset.zip\""
      ],
      "metadata": {
        "id": "1ygTL4kUInxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#switching to dataset directory\n",
        "!unzip  \"{zip_file_path}\" -d /content/ASLDataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6O2iO3hlf0S",
        "outputId": "06a7cc93-f0d4-43d6-ef30-59db3fdb4030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/TAMU Junior Year/AI4All/AI4ALL-Class-16-Group-2/ASL Dataset.zip\n",
            "replace /content/ASLDataset/ASL_Alphabet_Dataset/asl_alphabet_test/A_test.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ASLDataset/ASL_Alphabet_Dataset\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABPxREfmJ6EQ",
        "outputId": "ca11274e-3bdf-4f50-c674-e640659c8aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ASLDataset/ASL_Alphabet_Dataset\n",
            "asl_alphabet_test  asl_alphabet_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd asl_alphabet_test\n",
        "\n",
        "#testing dataset\n",
        "from IPython.display import Image\n",
        "Image('A_test.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "z2a5MFJXmxC2",
        "outputId": "fd2ead53-3a72-42fa-fe23-c351719b5a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ASLDataset/ASL_Alphabet_Dataset/asl_alphabet_test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../asl_alphabet_train\n",
        "\n",
        "#initialize class names for classification\n",
        "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'other']\n",
        "#label class names with numbers corresponding to each class in a dictionary format (0-26)\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "\n",
        "#defining image size in dataset\n",
        "IMAGE_SIZE = (200, 200)\n",
        "\n",
        "#print class names with corresponding numerical label\n",
        "print(class_names_label)"
      ],
      "metadata": {
        "id": "5WyoFDdcnQxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096b9fc4-06fe-41a7-c32f-0fe0135be0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ASLDataset/ASL_Alphabet_Dataset/asl_alphabet_train\n",
            "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'other': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing library dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sn; sn.set(font_scale=1.4)\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from math import ceil"
      ],
      "metadata": {
        "id": "Cx-kKr_4Y-th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merges del, nothing, and space folder in \"other\" folder\n",
        "\n",
        "# Define valid image extensions\n",
        "VALID_IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
        "\n",
        "if not os.path.exists('./other'):\n",
        "  os.makedirs('./other')\n",
        "\n",
        "if (os.path.exists('./nothing')):\n",
        "  for image in os.listdir('./nothing'):\n",
        "    s = os.path.join('./nothing', image) #gets path of image in nothing folder\n",
        "\n",
        "    if os.path.isfile(s) and os.path.splitext(image)[1].lower() in VALID_IMAGE_EXTENSIONS:\n",
        "        d = os.path.join('./other', image)  #makes path of image in other folder\n",
        "        shutil.move(s, d)  #moves image in nothing folder into other folder\n",
        "\n",
        "if (os.path.exists('./space')):\n",
        "  for image in os.listdir('./space'):\n",
        "    s = os.path.join('./space', image) #gets path of image in space folder\n",
        "    if os.path.isfile(s) and os.path.splitext(image)[1].lower() in VALID_IMAGE_EXTENSIONS:\n",
        "        d = os.path.join('./other', image)  #makes path of image in other folder\n",
        "        shutil.move(s, d)  #moves image in space folder into other folder\n",
        "\n",
        "if (os.path.exists('./del')):\n",
        "  for image in os.listdir('./del'):\n",
        "    s = os.path.join('./del', image) #gets path of image in del folder\n",
        "    if os.path.isfile(s) and os.path.splitext(image)[1].lower() in VALID_IMAGE_EXTENSIONS:\n",
        "        d = os.path.join('./other', image)  #makes path of image in other folder\n",
        "        shutil.move(s, d)  #moves image in del folder into other folder"
      ],
      "metadata": {
        "id": "yfANbFa8ajjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete empty folder paths\n",
        "folder_paths = ['./nothing', './del', './space']\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "  if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Deleted folder: {folder_path}\")\n",
        "  else:\n",
        "    print(f\"Folder not found or not a directory: {folder_path}\")\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kvNpkRMcVit",
        "outputId": "1c44ee99-e10c-436c-d11d-0de1e535a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder not found or not a directory: ./nothing\n",
            "Folder not found or not a directory: ./del\n",
            "Folder not found or not a directory: ./space\n",
            "\u001b[0m\u001b[01;34mA\u001b[0m/  \u001b[01;34mC\u001b[0m/  \u001b[01;34mE\u001b[0m/  \u001b[01;34mG\u001b[0m/  \u001b[01;34mI\u001b[0m/  \u001b[01;34mK\u001b[0m/  \u001b[01;34mM\u001b[0m/  \u001b[01;34mO\u001b[0m/      \u001b[01;34mP\u001b[0m/  \u001b[01;34mR\u001b[0m/  \u001b[01;34mT\u001b[0m/  \u001b[01;34mV\u001b[0m/  \u001b[01;34mX\u001b[0m/  \u001b[01;34mZ\u001b[0m/\n",
            "\u001b[01;34mB\u001b[0m/  \u001b[01;34mD\u001b[0m/  \u001b[01;34mF\u001b[0m/  \u001b[01;34mH\u001b[0m/  \u001b[01;34mJ\u001b[0m/  \u001b[01;34mL\u001b[0m/  \u001b[01;34mN\u001b[0m/  \u001b[01;34mother\u001b[0m/  \u001b[01;34mQ\u001b[0m/  \u001b[01;34mS\u001b[0m/  \u001b[01;34mU\u001b[0m/  \u001b[01;34mW\u001b[0m/  \u001b[01;34mY\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming all images in other to other1-other{n}...\n",
        "folder_path = './other'\n",
        "image_name_prefix = 'other'\n",
        "\n",
        "#Normalize folder_path to ensure no trailing slash\n",
        "folder_path = os.path.normpath(folder_path)\n",
        "\n",
        "#lists all images in the folder\n",
        "images = os.listdir(folder_path)\n",
        "\n",
        "#Rename each item\n",
        "for i, image in enumerate(images, start=1):\n",
        "  #Get current image's file path\n",
        "  old_path = os.path.join(folder_path, image)\n",
        "\n",
        "  #Construct new name w/ numerical ordering and file extension\n",
        "  new_name = f\"{image_name_prefix}{i}.jpg\"\n",
        "  new_path = os.path.join(folder_path, new_name)\n",
        "\n",
        "  #Rename image\n",
        "  if not os.path.exists(new_path):\n",
        "        os.rename(old_path, new_path)\n",
        "\n",
        "print(f\"Renamed {len(images)} images in the other folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFwnwm7rcwLp",
        "outputId": "d2ca0fd9-6e56-428d-a58f-2bf47a2d4c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed 16937 images in the other folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function used to train & test data\n",
        "def collectData():\n",
        "  img_paths = []\n",
        "  labels = []\n",
        "\n",
        "\n",
        "  for folder in os.listdir(\"./\"): #loop through all directories in current file path\n",
        "    label = class_names_label[folder] #folder names are same as class_names dictionary (will return a number) --> i.e. class_names_label[\"A\"] = 0\n",
        "\n",
        "    #Iterate through each image in our folder\n",
        "    for file in os.listdir(os.path.join(\"./\", folder)):\n",
        "      img_path = os.path.join(os.path.join(\"./\", folder), file)\n",
        "\n",
        "      img_paths.append(img_path) #append image to list\n",
        "      labels.append(label) #append label of imgae to list\n",
        "\n",
        "  return img_paths, labels\n",
        "\n",
        "#put all image file paths in image_paths list and all corresponding labels in labels list\n",
        "image_paths, labels = collectData()"
      ],
      "metadata": {
        "id": "n83cOYpgT2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#stratify on labels b/c far more data in other folder than the rest of the classes (also set random state during data testing)\n",
        "img_train, img_test, label_train, label_test = train_test_split(image_paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "print(len(img_train), len(label_train))\n",
        "print(len(img_test), len(label_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt4CeZDVyxFw",
        "outputId": "90e43fd2-8e82-4778-e550-fed53ad731ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178459 178459\n",
            "44615 44615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Step 1: Create a custom data generator\n",
        "def custom_data_generator(image_paths, labels, batch_size, datagen, target_size=(200, 200)):\n",
        "    while True:  # Infinite loop to keep generating batches\n",
        "        indices = np.random.permutation(len(image_paths))  # Shuffle data\n",
        "\n",
        "        for i in range(0, len(image_paths), batch_size):\n",
        "            batch_indices = indices[i:i + batch_size]\n",
        "            batch_image_paths = [image_paths[j] for j in batch_indices]\n",
        "            batch_labels = [labels[j] for j in batch_indices]\n",
        "\n",
        "            batch_images = []\n",
        "            for img_path in batch_image_paths:\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Error loading image: {img_path}\")\n",
        "                    continue  # Skip invalid images\n",
        "                img = cv2.resize(img, target_size)  # Resize to the desired shape (e.g., 200x200)\n",
        "                batch_images.append(img)\n",
        "\n",
        "            # If there are no valid images in the batch, skip this iteration\n",
        "            if len(batch_images) == 0:\n",
        "                continue\n",
        "\n",
        "            # Convert the list of images to a NumPy array\n",
        "            batch_images = np.array(batch_images)\n",
        "            batch_images = np.expand_dims(batch_images, axis=-1)  # Add channel dimension\n",
        "            batch_images = batch_images.astype('float32') / 255.0  # Normalize the images\n",
        "\n",
        "            # Apply data augmentation using flow\n",
        "            augmented_images = datagen.flow(batch_images, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "            # Yield augmented images and corresponding labels\n",
        "            for augmented_batch_images in augmented_images:\n",
        "                yield augmented_batch_images, np.array(batch_labels)  # Yield the batch of images and labels\n",
        "\n",
        "# Step 2: Define your ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale the pixel values\n",
        "    rotation_range=40,  # Random rotations\n",
        "    width_shift_range=0.2,  # Random horizontal shifts\n",
        "    height_shift_range=0.2,  # Random vertical shifts\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Zoom in and out\n",
        "    horizontal_flip=True,  # Randomly flip images\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "target_size = (200, 200)\n",
        "\n",
        "# Create the custom generator\n",
        "train_generator = custom_data_generator(img_train, label_train, batch_size, datagen, target_size)\n",
        "test_generator = custom_data_generator(img_test, label_test, batch_size, datagen, target_size)\n"
      ],
      "metadata": {
        "id": "hyo87FJZkSi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt at using tf.data API to have lazy pre-processing FAILED**"
      ],
      "metadata": {
        "id": "g7A6Ku17scs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use tensor flow lazy pre-processing (tf.data) in order to only load required data onto RAM\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_image(image_path, label):\n",
        "  image_path = image_path.numpy().decode('utf-8')  # Convert to string\n",
        "  img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Read as grayscale\n",
        "  img = cv2.resize(img, (200,200))\n",
        "  img = img.astype('float32') / 255.0  # Normalize the image\n",
        "  #img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "  return img, label\n",
        "\n",
        "def preprocess_image(image_path, label):\n",
        "  img, label = tf.py_function(\n",
        "      load_image,\n",
        "      inp=[image_path, label],\n",
        "      Tout=(tf.float32, tf.int32))\n",
        "\n",
        "  img.set_shape((200, 200, 3)) #define grayscale image numpy array shape\n",
        "  return img, label\n",
        "\n",
        "# Create a dataset from a list of image paths and labels\n",
        "def create_dataset(image_paths, labels, batch_size=32):\n",
        "    # Create a TensorFlow dataset from image paths and labels\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices((image_paths, labels)) #uses lazy processing to save memory\n",
        "\n",
        "    #Map the load_image function to the dataset (to load and preprocess images)\n",
        "    image_ds = path_ds.map(preprocess_image)\n",
        "\n",
        "    # Shuffle, batch, and prefetch for performance\n",
        "    image_ds = image_ds.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    #image_ds = image_ds.shuffle(buffer_size=1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return image_ds\n",
        "\n",
        "\n",
        "# Create the TensorFlow datasets for training & testing\n",
        "train_dataset = create_dataset(img_train, label_train)\n",
        "test_dataset = create_dataset(img_test, label_test)"
      ],
      "metadata": {
        "id": "qF6ckDtM_s95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=test_dataset, epochs=10, verbose=1)"
      ],
      "metadata": {
        "id": "Y3xUJpi3sb4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of tf.data API attempt"
      ],
      "metadata": {
        "id": "t7AG1_uFsivy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attempt to segment image arrays to prevent RAM overload below:**"
      ],
      "metadata": {
        "id": "5sEBGwEVAJ-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loop through each image path, open and resize the image, then append them to numpy arrays to train keras CNN with\n",
        "imageTrainList = []\n",
        "labelTrainList = []\n",
        "\n",
        "#Split data in 40,000 image segments to prevent overwhelming CPU\n",
        "for i in range(40001):\n",
        "  img_path = img_train[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTrainList.append(image)\n",
        "  labelTrainList.append(label_train[i])"
      ],
      "metadata": {
        "id": "nXA6yZjthDGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segment 2\n",
        "for i in range(40001,80001):\n",
        "  img_path = img_train[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTrainList.append(image)\n",
        "  labelTrainList.append(label_train[i])"
      ],
      "metadata": {
        "id": "t4KoYzWMyreo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segment 3\n",
        "for i in range(80001,120001):\n",
        "  img_path = img_train[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTrainList.append(image)\n",
        "  labelTrainList.append(label_train[i])"
      ],
      "metadata": {
        "id": "YE6QZcYVzsG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segment 4\n",
        "for i in range(120001,140001):\n",
        "  img_path = img_train[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTrainList.append(image)\n",
        "  labelTrainList.append(label_train[i])"
      ],
      "metadata": {
        "id": "zvC6qLabzzio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segment 5\n",
        "for i in range(140001,len(img_train)):\n",
        "  img_path = img_train[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTrainList.append(image)\n",
        "  labelTrainList.append(label_train[i])"
      ],
      "metadata": {
        "id": "TGiCRMupz3aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert training images to numpy arrays for keras usage\n",
        "imageTrainList = np.array(imageTrainList, dtype='float32')\n",
        "labelTrainList = np.array(labelTrainList, dtype='int32')"
      ],
      "metadata": {
        "id": "gU72AF7AzZUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle images for better training (standard procedure)\n",
        "imageTrainList, labelTrainList = shuffle(imageTrainList, labelTrainList, random_state=42)\n",
        "\n",
        "print(\"Training Image & Label array conversion successful!\")"
      ],
      "metadata": {
        "id": "2ZfMG1u-9yHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator( #automatic data augmentation\n",
        "    rescale=1./255,  # Normalize pixel values to range [0, 1]\n",
        "    rotation_range=40,  # Random rotation between 0 and 40 degrees\n",
        "    width_shift_range=0.2,  # Horizontal shift\n",
        "    height_shift_range=0.2,  # Vertical shift\n",
        "    shear_range=0.2,  # Random shear transformation\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flip\n",
        "    fill_mode='nearest'  # How to fill newly created pixels\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "-TmAIGgO2ioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using datagenerator, generate batches of data from numpy array lists\n",
        "train_generator = datagen.flow(imageTrainList, labelTrainList, batch_size=32)"
      ],
      "metadata": {
        "id": "zadKp29t4gsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Do the same w/o shuffling for testing\n",
        "imageTestList = []\n",
        "labelTestList = []\n",
        "\n",
        "for i in range(len(img_test)):\n",
        "  img_path = img_test[i]\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "  imageTestList.append(image)\n",
        "  labelTestList.append(label_test[i])"
      ],
      "metadata": {
        "id": "d9VrA1pyv5_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert training images to numpy arrays for keras usage\n",
        "imageTestArray = np.array(imageTestList, dtype='float32')\n",
        "labelTestArray = np.array(labelTestList, dtype='int32')\n",
        "\n",
        "print(\"Testing Image & Label array conversion successful!\")"
      ],
      "metadata": {
        "id": "1ZLBysa49-dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End of image segmentation attempt**"
      ],
      "metadata": {
        "id": "FTw8z-SpBhBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating CNN with keras\n",
        "#This CNN has:\n",
        "#1 hidden layer\n",
        "#Input layer = convolution layer -> also followed by MaxPoolingLayer\n",
        "#Hidden layer of another convolution layer & MaxPoolingLayer\n",
        "#flatten outputs to reduce the number of features and have an output layer consisting of a dense relu layer & dense softmax layer\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Input layer (no need to specify input_shape if it's the first layer)\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(200, 200, 1)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),  # Corrected pooling layer\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),  # Corrected pooling layer\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),  # Corrected pooling layer\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    # Flatten the feature maps before passing to dense layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    # Output layer with softmax activation for classification\n",
        "    tf.keras.layers.Dense(27, activation='softmax')  # Assuming 27 classes\n",
        "])"
      ],
      "metadata": {
        "id": "cK1NjkYekwb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5Cqbhkdku5c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "TKU5M5e5c1yt",
        "outputId": "c476736e-56a9-4bec-9f53-9f67c5e3d623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_40\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_40\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_108 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m320\u001b[0m \n",
              "\n",
              " conv2d_109 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)                   \u001b[38;5;34m9,248\u001b[0m \n",
              "\n",
              " max_pooling2d_86 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)                       \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_110 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m18,496\u001b[0m \n",
              "\n",
              " conv2d_111 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m36,928\u001b[0m \n",
              "\n",
              " max_pooling2d_87 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_112 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m73,856\u001b[0m \n",
              "\n",
              " conv2d_113 (\u001b[38;5;33mConv2D\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)                  \u001b[38;5;34m147,584\u001b[0m \n",
              "\n",
              " max_pooling2d_88 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_23 (\u001b[38;5;33mFlatten\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80000\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_80 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                       \u001b[38;5;34m40,960,512\u001b[0m \n",
              "\n",
              " dropout_24 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_81 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)                            \u001b[38;5;34m13,851\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv2d_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              "\n",
              " conv2d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> \n",
              "\n",
              " max_pooling2d_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
              "\n",
              " conv2d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
              "\n",
              " max_pooling2d_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
              "\n",
              " conv2d_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
              "\n",
              " max_pooling2d_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">40,960,512</span> \n",
              "\n",
              " dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">13,851</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,260,795\u001b[0m (157.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,260,795</span> (157.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,260,795\u001b[0m (157.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,260,795</span> (157.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check that image & label shape are as expected\n",
        "for images, labels in train_dataset.take(1):\n",
        "    print(images.shape)  # Expected: (batch_size, 200, 200, 1)\n",
        "    print(labels.shape)  # Expected: (batch_size,)\n",
        "    print(labels.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X_Nt8leR_pG",
        "outputId": "ad690b8d-f164-4184-e94c-21b4f0b565be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 200, 200, 3)\n",
            "(32,)\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model with one batch and check if shape of output is expected\n",
        "for images, labels in train_dataset.take(1):\n",
        "    predictions = model(images)  # Forward pass\n",
        "    print(predictions.shape)  # Should print: (32, 27) if output layer has 27 classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPlVC9nKSzZN",
        "outputId": "9296d7e6-fa2f-445d-9c7d-4d899f5f87c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define keras callback functions to stop early & reduce training when notcing no increase in accuracy\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0.001,\n",
        "                              patience= 5,\n",
        "                              restore_best_weights= True,\n",
        "                              verbose = 0)\n",
        "\n",
        "reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                         patience = 2,\n",
        "                                         factor=0.5 ,\n",
        "                                         verbose = 1)"
      ],
      "metadata": {
        "id": "hOQFoSZciY3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually check one batch of images and labels from the generator\n",
        "for images, labels in custom_data_generator(image_paths, labels, batch_size=32, datagen=datagen, target_size=(200, 200)):\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "    break  # Exit after one batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5m739I-mQSW",
        "outputId": "e7593e40-99a0-4a11-9004-ca57b56a968d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: (32, 200, 200, 1)\n",
            "Labels shape: (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epoch_steps = ceil(len(img_train) / batch_size)\n",
        "validation_steps = ceil(len(img_test) / batch_size)\n",
        "#testing = model.fit(train_generator, epochs=30, validation_data=test_generator, steps_per_epoch=(epoch_steps), callbacks=[early_stopping, reduce_learning_rate], verbose=1)\n",
        "testing = model.fit(train_generator, epochs=30, validation_data=test_generator, steps_per_epoch=9, validation_steps=10, callbacks=[early_stopping, reduce_learning_rate], verbose=1)"
      ],
      "metadata": {
        "id": "0FgzKA3pvy1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "efcf39d3-4957-4042-83f2-b8be4d05c4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NumpyArrayIterator' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-289-238cdb693514>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#testing = model.fit(train_generator, epochs=30, validation_data=test_generator, steps_per_epoch=(epoch_steps), callbacks=[early_stopping, reduce_learning_rate], verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_learning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in test_generator:\n",
        "    print(data)  # This should print batches of images and labels\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R-K4lBG5W8f",
        "outputId": "3ddb0234-5e6d-4cce-c67a-d218ebba4f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[[[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00043895]],\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00043374]],\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044137],\n",
            "         [0.00043267]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00045908],\n",
            "         [0.00044625],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00045387],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00044867],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]]],\n",
            "\n",
            "\n",
            "       [[[0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         ...,\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ]],\n",
            "\n",
            "        [[0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         ...,\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ]],\n",
            "\n",
            "        [[0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         ...,\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ],\n",
            "         [0.0004306 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00045517],\n",
            "         [0.00045542],\n",
            "         [0.00045568],\n",
            "         ...,\n",
            "         [0.00216531],\n",
            "         [0.00149073],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00046136],\n",
            "         [0.00046136],\n",
            "         [0.00046136],\n",
            "         ...,\n",
            "         [0.00216716],\n",
            "         [0.00151494],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00045666],\n",
            "         [0.0004564 ],\n",
            "         [0.00045615],\n",
            "         ...,\n",
            "         [0.0021684 ],\n",
            "         [0.00153537],\n",
            "         [0.00044598]]],\n",
            "\n",
            "\n",
            "       [[[0.00041522],\n",
            "         [0.00041522],\n",
            "         [0.00041522],\n",
            "         ...,\n",
            "         [0.00096752],\n",
            "         [0.00099114],\n",
            "         [0.00098253]],\n",
            "\n",
            "        [[0.00041522],\n",
            "         [0.00041522],\n",
            "         [0.00041522],\n",
            "         ...,\n",
            "         [0.00099167],\n",
            "         [0.00102733],\n",
            "         [0.00102227]],\n",
            "\n",
            "        [[0.00041522],\n",
            "         [0.00041522],\n",
            "         [0.00041522],\n",
            "         ...,\n",
            "         [0.00097473],\n",
            "         [0.00099032],\n",
            "         [0.00096464]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.0004575 ],\n",
            "         [0.00044882],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00045574],\n",
            "         [0.00045058],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.00045399],\n",
            "         [0.00045234],\n",
            "         [0.00044598]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[0.00044419],\n",
            "         [0.00045841],\n",
            "         [0.00045557],\n",
            "         ...,\n",
            "         [0.00044609],\n",
            "         [0.00043749],\n",
            "         [0.00043316]],\n",
            "\n",
            "        [[0.00046339],\n",
            "         [0.00043441],\n",
            "         [0.00047477],\n",
            "         ...,\n",
            "         [0.00046039],\n",
            "         [0.00047328],\n",
            "         [0.0004736 ]],\n",
            "\n",
            "        [[0.00046943],\n",
            "         [0.00041907],\n",
            "         [0.00048981],\n",
            "         ...,\n",
            "         [0.00046452],\n",
            "         [0.00045909],\n",
            "         [0.00045049]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.0004293 ],\n",
            "         [0.00046106],\n",
            "         [0.00046066]],\n",
            "\n",
            "        [[0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         ...,\n",
            "         [0.0004197 ],\n",
            "         [0.00045146],\n",
            "         [0.00047026]],\n",
            "\n",
            "        [[0.00044439],\n",
            "         [0.0004401 ],\n",
            "         [0.0004358 ],\n",
            "         ...,\n",
            "         [0.00042034],\n",
            "         [0.00044186],\n",
            "         [0.00047362]]],\n",
            "\n",
            "\n",
            "       [[[0.00045166],\n",
            "         [0.00045867],\n",
            "         [0.00045704],\n",
            "         ...,\n",
            "         [0.00046136],\n",
            "         [0.00045194],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.0004538 ],\n",
            "         [0.0004468 ],\n",
            "         [0.00045218],\n",
            "         ...,\n",
            "         [0.00045968],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00044947],\n",
            "         [0.0004603 ],\n",
            "         [0.00045329],\n",
            "         ...,\n",
            "         [0.0004531 ],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00045287],\n",
            "         [0.00043855],\n",
            "         [0.00043698],\n",
            "         ...,\n",
            "         [0.00044311],\n",
            "         [0.0004361 ],\n",
            "         [0.0004306 ]],\n",
            "\n",
            "        [[0.00044629],\n",
            "         [0.00043197],\n",
            "         [0.00044356],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.0004426 ]],\n",
            "\n",
            "        [[0.00043971],\n",
            "         [0.00043582],\n",
            "         [0.00045014],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]]],\n",
            "\n",
            "\n",
            "       [[[0.00039213],\n",
            "         [0.00038887],\n",
            "         [0.00040285],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00044213],\n",
            "         [0.00043095],\n",
            "         [0.00041977],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        [[0.00045752],\n",
            "         [0.00045472],\n",
            "         [0.00045193],\n",
            "         ...,\n",
            "         [0.00044598],\n",
            "         [0.00044598],\n",
            "         [0.00044598]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00189266],\n",
            "         [0.00190579],\n",
            "         [0.00190372],\n",
            "         ...,\n",
            "         [0.00045444],\n",
            "         [0.00045723],\n",
            "         [0.00046003]],\n",
            "\n",
            "        [[0.00189158],\n",
            "         [0.00189328],\n",
            "         [0.00189802],\n",
            "         ...,\n",
            "         [0.00044194],\n",
            "         [0.00044473],\n",
            "         [0.00044753]],\n",
            "\n",
            "        [[0.00189158],\n",
            "         [0.00189158],\n",
            "         [0.00189671],\n",
            "         ...,\n",
            "         [0.00043177],\n",
            "         [0.00043223],\n",
            "         [0.00043503]]]], dtype=float32), array([ 3,  1, 26,  5, 23, 23,  0, 26, 14, 26, 23,  0, 17, 14, 24, 12,  5,\n",
            "       21,  1, 22, 18, 23, 11, 24,  7, 16, 26,  4,  0, 26,  5,  2]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ASLClassifier.h5')"
      ],
      "metadata": {
        "id": "S6R_pgj_lGRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}